# MOSAIC AI CHOLERA DATA COLLECTION - 4-AGENT PROGRESSIVE SEARCH WORKFLOW

## OVERVIEW
**Target Country**: Benin (BEN)

This workflow implements a progressive 4-agent system for maximizing cholera surveillance data discovery while maintaining rigorous quality standards. Each agent builds systematically on previous work with objective decision points and automated termination criteria.

## WORKFLOW CONTROL PARAMETERS

### **Progressive Targets**:
- Agent 1: Baseline establishment (8-phase protocol completion)
- Agent 2: Minimum 50% data observation increase
- Agent 3: Minimum 25% additional data observation increase
- Agent 4: ≤1% yield increase OR <3 new observations

### **Quality Gates** (Agents 1-3):
- ≥90% Level 1-2 source reliability maintained
- 100% validation pass rate achieved
- Zero-transmission periods preserved as epidemiologically relevant
- Complete documentation and audit trail

### **Efficiency Controls**:
- Objective stopping criteria prevent over-searching
- Pause-and-review checkpoints enable resource optimization
- Progressive intensity avoids unnecessary early work
- Saturation detection prevents diminishing returns

### **Automation Parameters**:
- Execute all agents sequentially without user prompts
- Log progress metrics after each agent completion
- Report consolidated results only at conclusion
- Maintain quality standards throughout progression
- **Report end-to-end total run time for complete 4-agent workflow**

## IMPLEMENTATION NOTES

### **Termination Logic**:
- Objective decision points reduce subjective interpretation
- Multiple stopping criteria ensure efficient completion
- Quality gates prevent premature termination

### **Success Metrics**:
- Total sources discovered across all agents
- Total observations extracted and validated
- Quality distribution (Level 1-4 source breakdown)
- Temporal coverage completeness
- Geographic granularity achieved
- Zero-transmission period validation
- **Complete workflow execution time (start to finish)**


**SEQUENTIAL AGENTIC WORKFLOW IS AS FOLLOWS:**

## AGENT 1: BASELINE ESTABLISHMENT
**Objective**: Execute foundational ULTRA DEEP SEARCH protocol

**Task**: Execute the ultra deep search protocol in the ./data/BEN/search_protocol_BEN.txt file.

**Quality Requirements**:
- Must maintain ≥90% Level 1-2 source reliability
- Must achieve 100% validation pass rate
- Document any quality degradation with justification

**Deliverables**:
- Complete 8-phase ULTRA DEEP SEARCH methodology
- Pass all 6 quality gates
- Generate baseline dataset with dual-reference indexing

**Checkpoint Requirements**:
*Pause and report: X sources found, Y observations added, baseline established*
*Quality metrics: A% Level 1-2 sources, B% validation success*
*Baseline dataset: Total sources, total observations, temporal coverage*

## DATA OUTPUT FORMATTING
- ALL AGENTS MUST ADHERE TO THE DATA FORMATTING RULES DEFINED IN THE ./data/BEN/search_protocol_BEN.txt file

|

## AGENT 2: SYSTEMATIC EXPANSION
**Trigger**: Automatically execute after Agent 1 completion
**Objective**: Enhanced data discovery through systematic expansion

**EXPANDED ULTRA DEEP SEARCH PROTOCOL**
There should be more data observations. Do a more extensive deep search to find more data sources and more data observations. Do an extended search to increase the number of data sources and data observations. Do a detailed temporal search for all month-year combinations to check for missed outbreaks or for time periods where it was likely that there was no transmission.

**Target**: Aim for a minimum 50% increase in data observations from Agent 1 baseline

This expanded search protocol should include the following tasks:

☐ Extended Temporal Search - Month-year combinations 1970-PRESENT systematic coverage
☐ Additional Source Discovery - ProMED, news archives, government databases, academic preprints
☐ Zero Transmission Validation - Detailed documentation of no-case periods with evidence
☐ Granular Geographic Search - District and municipality level data discovery
☐ Enhanced Data Extraction - Extract ALL available data points from discovered sources
☐ Quality Expansion Validation - Validate all newly discovered sources and data points

**Quality Requirements**:
- Must maintain ≥90% Level 1-2 source reliability
- Must achieve 100% validation pass rate
- Preserve epidemiologically relevant zero-transmission periods

**Success Criteria**: Continue until data yield increase <20% in single iteration

**Checkpoint Requirements**:
*Pause and report: X sources found, Y observations added, Z% improvement from baseline*
*Quality metrics: A% Level 1-2 sources, B% validation success*
*Enhancement verification: Target 40% minimum improvement achieved (Yes/No)*
*Next stage justification: Continue/Stop decision rationale*

|

## AGENT 3: MAXIMUM DISCOVERY WITH GAP INVESTIGATION
**Trigger**: Automatically execute after Agent 2 completion
**Objective**: Achieve discovery saturation through ultra-extensive search

**ULTRA-EXTENSIVE SEARCH EXPANSION FOR MAXIMUM DATA YIELD**

The results are improved, now please expand your search to increase data yield if possible and investigate any data gaps. Keep time periods where you are confident that no transmission occurred. These are epidemiologically relevant.

**Target**: Aim for a minimum 25% increase in data observations from Agent 2 results

This ultra-extensive search should include the following tasks:

☐ Ultra-Extensive Temporal Mining - Systematic month-year searches for all missing periods
☐ Deep Archive Excavation - Internet Archive systematic mining for broken/moved sources
☐ Institutional Website Deep Dives - Government ministries, universities, hospitals
☐ Multi-language Expansion - French, Local languages systematic coverage
☐ Cross-Reference Chain Following - Follow ALL citation chains to maximum depth
☐ Gap Investigation - Analyze and validate remaining data gaps with evidence
☐ Enhanced Quality Validation - Re-validate all sources with expanded criteria

**Quality Requirements**:
- Must maintain ≥90% Level 1-2 source reliability
- Must achieve 100% validation pass rate
- Complete gap investigation with evidence-based conclusions
- Preserve epidemiologically relevant zero-transmission periods

**Success Criteria**: Achieve discovery saturation (≤5% yield increase) OR maximum 3 iterations reached

**Checkpoint Requirements**:
*Pause and report: X sources found, Y observations added, Z% improvement from Agent 2*
*Quality metrics: A% Level 1-2 sources, B% validation success*
*Gap investigation: Complete analysis of missing periods with evidence*
*Discovery status: Saturation achieved (Yes/No), rationale provided*
*Next stage justification: Continue/Stop decision rationale*

|

## AGENT 4: SATURATION MONITORING AND OPTIMIZATION
**Trigger**: Automatically execute after Agent 3 completion
**Objective**: Final optimization and saturation confirmation

**SATURATION PROTOCOL**
Continue expanded ultra deep search protocols until there is <1% increase in data observations gained or saturation occurs.

**Termination Criteria** (ANY of the following):
- Data yield increase ≤1% in final iteration
- <3 new observations gained in iteration
- Discovery saturation achieved across all search categories
- Maximum search depth reached (citations followed to depth 4+)
- All quality gates passed for final dataset

**Quality Requirements**:
- May use ANY LEVEL source reliability as long as the 'confidence_weight' variable is identified
- Must achieve 100% validation pass rate
- Final quality audit of complete dataset
- Comprehensive documentation of saturation rationale

**Final Deliverables**:
- Consolidated dataset with all quality validations
- Complete search methodology documentation
- Saturation analysis and stopping rationale
- Final performance metrics summary
- **Complete end-to-end workflow execution time report**

**Final Checkpoint Requirements**:
*Final report: Total X sources found, Y observations added, Z% total improvement*
*Quality metrics: A% Level 1-2 sources, B% validation success, C% temporal coverage*
*Saturation confirmation: Discovery saturation achieved, stopping criteria met*
*Dataset quality: Final validation summary, confidence assessment*
*Execution time: Total workflow runtime from start to finish*
