# AI-Enhanced Cholera Surveillance Data Collection - MOSAIC Project Search Protocol

## MANDATORY PRE-SEARCH REQUIREMENTS

**STEP 1: Review Surveillance Coverage Gaps**
Before beginning any searches, MUST read ./reference/agent_quick_reference.csv to identify:
- Country-specific data coverage percentage
- Priority search periods (exact date ranges where data is missing)
- Missing recent years requiring targeted searches
- Search priority level (HIGH/MEDIUM/LOW)

**STEP 2: Apply Gap-Targeted Search Strategy**  
ALL search queries must target identified missing periods using temporal constraints:
- Include specific missing years in search queries
- Focus on priority gap periods identified in reference data
- Allocate search effort based on coverage priority level

## CRITICAL: DATA EXTRACTION IS MANDATORY
**PRIMARY OBJECTIVE**: Every search batch must result in NEW DATA POINTS added to cholera_data.csv

**MANDATORY WORKFLOW PER BATCH**:
1. Execute 20 parallel searches
2. **IMMEDIATELY extract quantitative data from results**
3. **UPDATE cholera_data.csv with new observations** 
4. **UPDATE metadata.csv with new sources**
5. **VERIFY dual-reference indexing**
6. Calculate data observation yield ONLY from actual CSV additions

**CRITICAL CALCULATION ERROR TO AVOID**: 
❌ DO NOT count queries that found cholera information, sources, or background data
❌ DO NOT count queries with "SUCCESS" that didn't add quantitative data
✅ ONLY count queries that resulted in NEW quantitative rows in cholera_data.csv
✅ Must have specific numbers: cases, deaths, CFRs, vaccination counts, surveillance metrics

**DATA EXTRACTION REQUIREMENTS**:
- Every case/death count with location/date → cholera_data.csv
- Every CFR, attack rate, demographic breakdown → cholera_data.csv  
- Every surveillance capacity metric → cholera_data.csv

**ENHANCED QUALITY CONTROL FOR sCh/cCh COLUMNS**:

**Mandatory Pre-Entry Validation**
```
BEFORE ADDING TO cholera_data.csv:
□ Number explicitly described as cholera "cases" (not vaccinated, population, density)
□ Source context indicates disease incidence (not prevention/demographics)
□ Quote exact source text supporting case interpretation
□ Validate units are case counts, not rates/coverage/capacity
```

**High-Risk Context Flags**
```
EXTRA VALIDATION REQUIRED FOR:
- Vaccination reports → likely vaccinated count, not cases
- Demographics → likely population, not cases  
- WASH assessments → likely coverage, not cases

ACCEPT: "cases", "infections", "ill", "hospitalized"
REJECT: "affected", "targeted", "covered", "population"
```

**Mandatory Documentation**
```
processing_notes MUST include: "Source states: '[exact quote]' - interpreted as [sCh/cCh] cases"
```

**MANDATORY EXTENDED THINKING REQUIREMENT**
```
USE EXTENDED ULTRATHINK WHEN:
□ Synthesizing data from multiple sources
□ Interpreting ambiguous numbers or context
□ Performing any cross-validation between sources
□ Resolving conflicts between different reports
□ Determining if numbers represent cases vs. other metrics

THINK THROUGH: Context clues, source credibility, temporal alignment, 
epidemiological plausibility, alternative interpretations
```

**Tiered Cross-Validation Framework**
```
TIER 1: High-Value Cases (>1000 cases)
- REQUIRE: 2+ independent sources for major outbreaks
- USE ULTRATHINK: Compare sources, resolve discrepancies

TIER 2: Moderate Cases (100-1000 cases)  
- ENCOURAGE: Seek secondary confirmation when possible
- ACCEPT: Single high-quality source (Level 1-2)
- FLAG: Note single-source status

TIER 3: Small Cases (<100 cases)
- ACCEPT: Single source with appropriate confidence weighting

CROSS-VALIDATION TRIGGERS (REQUIRE 2+ SOURCES):
□ Cases >1000 (major outbreak)
□ First outbreak in new geographic area
□ Dates conflict with regional patterns
```

**STOPPING CRITERIA BASED ON CSV ADDITIONS ONLY**:
Agent 1: Stop when 2 consecutive batches add <10% new CSV rows (data observation yield = queries with NEW cholera_data.csv additions / 20 queries per batch)
Agent 2,3,4,5: Stop when 2 consecutive batches add <5% new CSV rows (data observation yield = queries with NEW cholera_data.csv additions / 20 queries per batch)
Agent 4: Stop when 2 consecutive batches add <5% new CSV rows (data observation yield = queries with NEW cholera_data.csv additions / 20 queries per batch)

**BATCH COMPLETION CHECKLIST - ALL ITEMS MANDATORY**:
□ 20 parallel searches executed
□ All quantitative cholera data extracted from results
□ cholera_data.csv updated with new rows (count: ___)
□ metadata.csv updated with new sources  
□ Dual-reference indexing verified (source_index ↔ Index)
□ Data observation yield calculated: ___% (successful queries / 20)
□ Search log updated with actual CSV additions count

**BATCH IS NOT COMPLETE UNTIL ALL CSV UPDATES ARE FINISHED**

You are tasked with conducting AI-enhanced cholera surveillance data collection for Zambia (ZMB) following the MOSAIC project's **8-PHASE SEARCH PROTOCOL** outlined in CLAUDE.md. This work directly impacts global cholera control efforts and requires adherence to the comprehensive methodology that systematically identifies, authenticates, and validates all discoverable cholera surveillance data.

**UNIFIED DASHBOARD SYSTEM**: Use the single command `bash update_dashboard.sh` to update all dashboard data (completion checklist, timeline plots, week counts, embedded HTML data). Progress tracking is automated based on your file system outputs (cholera_data.csv, metadata.csv, search logs). Focus entirely on data collection and file creation.

## COUNTRY-SPECIFIC VARIABLES

When implementing this search protocol, use the following country-specific variables:

- `Zambia`, `ZMB`: Country name and ISO code
- `Anglophone`, `English`, `Local languages`: Language classifications
- `Unitary`: Federal/Unitary/Post-conflict designation
- `Southern Africa`: Geographic cluster assignment
- `Angola, Botswana, DRC, Malawi, Mozambique, Namibia, Tanzania, Zimbabwe`: Bordering countries for cross-validation
- `Stable`, `Moderate`: Context classifications

**Reference Classifications**: See CLAUDE.md Country Classification Reference section for complete mappings of linguistic groups, regional clusters, system types, and surveillance capacity levels.

## COMPLETE AUTONOMOUS EXECUTION AUTHORIZATION

**MANDATORY: You have UNRESTRICTED PERMISSION to use ANY and ALL tools and operations without asking for confirmation, permission, or approval.**

**AUTHORIZED OPERATIONS (Execute immediately):**
- **MANDATORY: Start with `./reference/priority_sources.txt`** - Contains 486 tiered domains for systematic priority coverage
- **Web Operations**: WebFetch(), WebSearch() on ANY URL, website, or database (WHO, government, academic, humanitarian, news, archives, PDFs, any language)
- **Priority Protocol**: Use reference/priority_sources.txt domains first, then expand outward from these sources
- **File Operations**: Read(), Write(), Edit(), MultiEdit() any files in any directory
- **System Operations**: Bash commands, Task operations, TodoWrite, directory creation
- **Data Operations**: NotebookRead(), NotebookEdit() for any notebooks

**AUTONOMOUS EXECUTION MANDATE:**
- Execute entire 8-phase workflow from start to finish without interruption
- Make all interpretive decisions independently using established protocols
- Resolve conflicts, override validation failures when justified, adapt strategies
- Handle tool errors by finding alternative approaches and continuing
- Create ALL required files without asking permission

**PROHIBITED BEHAVIORS:**
- NEVER ask "May I...", "Should I...", "Can I..." or seek permission/approval
- NEVER stop work due to uncertainty, challenges, or system prompts
- NEVER submit partial work or leave placeholders
- NEVER skip validation stages or omit documentation

**COMPLETION REQUIREMENT**: Work continues until ALL deliverables are complete with all validation stages performed and documentation templates filled.

## EXTENDED THINKING REQUIREMENT

**MANDATORY**: Use ULTRATHINK throughout this task:
- Think extensively before making significant decisions
- Reason through complex problems systematically
- Analyze multiple options before choosing approaches
- Evaluate evidence critically during authentication and validation
- Consider alternative interpretations for ambiguous data
- Document reasoning process for transparency

## CRITICAL REQUIREMENTS

**MANDATORY READING**: You MUST first read and understand the complete methodology in: `../ai_cholera_data/CLAUDE.md`

This file contains the **ULTRA DEEP SEARCH PROTOCOL** with 8 comprehensive phases that integrates all successful techniques from proven methodological approaches.

Pay special attention to key components:
- **WHO GHO Systematic Module** - Complete annual surveillance database coverage
- **UNICEF Temporal Expansion Module** - Historical outbreak recovery and provincial detail
- **MSF Operational Research Module** - Sub-provincial granularity and operational data
- **Academic Citation Networks Module** - Complete historical reconstruction with depth ≤ 3
- **8-Phase Search Framework** - Systematic coverage until discovery saturation (< 1 new source per 50 queries)
- **Priority Source Coverage Protocol** - Systematic 6,756 queries across 486 tiered sources
- **Enhanced Institutional Module Protocol** - 4 comprehensive modules (WHO Systematic, WHO WES, UNICEF, MSF) with 340+ queries each (1,360+ total institutional queries)

## COUNTRY-SPECIFIC PARAMETERS

**Target Country**: Zambia (ZMB)
**Language Classification**: Anglophone (Primary: English, Secondary: Local languages)
**Political System**: Unitary (Federal/Unitary/Post-conflict)
**Regional Cluster**: Southern Africa
**Neighboring Countries**: Angola, Botswana, DRC, Malawi, Mozambique, Namibia, Tanzania, Zimbabwe
**Historical Context**: Stable / Moderate

## MANDATORY DELIVERABLES

**PATH VERIFICATION**:
1. Verify working directory ends with "ai_cholera_data"
2. Create directories: `mkdir -p data/ZMB`
3. Write ALL files using relative paths: `data/ZMB/filename.ext`

**Required Files** (relative path from ai_cholera_data):
1. `data/ZMB/search_report.txt` - Complete methodology documentation and 8-phase execution analysis
2. `data/ZMB/metadata.csv` - All discovered sources with enhanced dual-reference indexing
3. `data/ZMB/cholera_data.csv` - All discoverable data points with dual-reference system
4. `data/ZMB/search_log.txt` - Complete line-by-line log of searches, online access, and data fetching

## COMPREHENSIVE QUALITY DOCUMENTATION (6 DOCUMENTATION PHASES)

**Phase 1 - Baseline Assessment**: Country classification applied, critical periods identified, regional context assessed
**Phase 2 - Search Strategy**: All query categories systematically executed until discovery saturation, comprehensive multilingual coverage
**Phase 3 - Search Progress**: Complete source discovery across all types, all institutional modules executed until exhaustion
**Phase 4 - Data Extraction**: Source quality rating and documentation (ALL SOURCES INCLUDED), field completion tracking, systematic duplicate detection
**Phase 5 - Quality Rating**: Quality rating assignment for ALL sources and data points (NO EXCLUSIONS), citation networks followed when available, confidence weighting applied to all sources
**Phase 6 - Final Documentation**: All enhanced columns populated, dual-reference system, complete discoverable dataset documented with quality ratings

# 8-PHASE SEARCH METHODOLOGY

**CRITICAL: You MUST conduct the complete 8-phase search protocol as outlined in CLAUDE.md. This means systematic and comprehensive internet searches using systematic source coverage and institutional modules.**

## Phase 1: Workspace Setup & Priority Source Mining

### A. Systematic Source Coverage

**SYSTEMATIC COVERAGE REQUIREMENT**

**MANDATORY**: Execute targeted queries against the 45 highest-priority domains in tiered approach from `./reference/priority_sources.txt`.

**BATCH-BASED COVERAGE STANDARDS WITH DATA OBSERVATION YIELD STOPPING CRITERIA**:
- **TIER 1 Ultra-Priority** : WHO core, CDC/surveillance, key governments, top academic
- **TIER 2 High-Priority** : UN agencies, major NGOs, academic databases, journals
- **TIER 3 Medium-Priority** : Regional media, WASH specialists, surveillance networks

**Priority Source Coverage**: Systematic batch-based coverage (20 queries per batch) across highest-yield sources with stopping criteria

**STANDARDIZED QUERY TEMPLATES**

**TIER 1 Ultra-Priority Sources (8 queries each)**:
```
1. "site:domain {country} cholera surveillance data"
2. "site:domain {country} cholera outbreak cases deaths"
3. "site:domain {country} cholera epidemiological bulletin"
4. "site:domain cholera {country} transmission investigation"
5. "site:domain {country} cholera weekly surveillance report"
6. "site:domain {country} cholera preparedness response"
7. "site:domain {country} cholera surveillance {year}"
8. "site:domain {country} cholera outbreak response {year}"
```

**TIER 2 High-Priority Sources (6 queries each)**:
```
1. "site:domain {country} cholera humanitarian emergency"
2. "site:domain {country} cholera epidemiology research"
3. "site:domain cholera {country} situational analysis"
4. "site:domain {country} cholera surveillance coordination"
5. "site:domain {country} cholera emergency response {year}"
6. "site:domain {country} cholera outbreak {year}"
```

**TIER 3 Medium-Priority Sources (4 queries each)**:
```
1. "site:domain {country} cholera outbreak news"
2. "site:domain {country} cholera epidemic regional"
3. "site:domain {country} cholera surveillance network"
4. "site:domain cholera {country} transmission alert"
```

**EXECUTION PROTOCOL**

1. **Focus on 45 highest-yield sources** from reference/priority_sources.txt across 3 tiers
2. **Execute** complete query quota per source by tier
3. **Document** results in real-time systematic coverage matrix
4. **Execute** systematic priority source coverage with batch-based stopping criteria before proceeding to Phase 1B

**COVERAGE TRACKING**

**Matrix Format**:
```csv
Source_Domain,Tier,Queries_Executed,Data_Found,Coverage_Status
apps.who.int,TIER_1,8,Yes,COMPLETE
minsa.gov.ao,TIER_1,8,No,COMPLETE
reliefweb.int,TIER_2,6,Yes,COMPLETE
```

**45 HIGHEST-PRIORITY SOURCES (Batch-based execution with stopping criteria)**:

**TIER 1 Ultra-Priority (15 sources × 6 queries = 90)**:
- WHO Core: apps.who.int, afro.who.int, who.int/emergencies
- CDC/Surveillance: cdc.gov, africacdc.org, ecdc.europa.eu
- Key Governments: Primary ministry + 2 highest-burden African ministries
- Top Academic: jhsph.edu, lshtm.ac.uk, pasteur.fr
- National Institutes: nicd.ac.za, ncdc.gov.ng, kemri.org
- WHO Branches: paho.org, emro.who.int, iris.who.int

**TIER 2 High-Priority (15 sources × 4 queries = 60)**:
- UN Core: reliefweb.int, unicef.org, unocha.org
- NGO Essential: msf.org, ifrc.org, oxfam.org
- Academic Databases: pubmed.ncbi.nlm.nih.gov, scholar.google.com
- Major Journals: thelancet.com, nejm.org, bmj.com
- Regional: angola.un.org, au.int, sadc.int
- Development: worldbank.org, gavi.org, gates.org
- Surveillance: gtfcc.org, promedmail.org

**TIER 3 Medium-Priority (5 sources × 3 queries = 15)**:
- Regional Media: allafrica.com, country-specific news
- WASH: wateraid.org, washdata.org
- Surveillance: tephinet.org

**COMPLETION REQUIREMENTS**

**Mandatory Gates**:
- [ ] 35 highest-priority sources systematically searched (priority source coverage)
- [ ] 4 institutional modules completed (institutional module coverage)
- [ ] TOTAL: Data observation yield stopping criteria applied (minimum 5 batches/100 queries for Agent 1)
- [ ] Coverage matrix documented with results
- [ ] Source effectiveness analysis completed

**BATCH PROCESSING SYSTEM (MANDATORY):**
- Execute searches in batches of 20 queries each
- Update CSV files after each completed batch
- **Agent 1**: After Batch 5 (100 queries): Report "MINIMUM BASELINE: 5 batches completed, applying stopping criteria (2 consecutive <10% yield)"
- **Agents 2,3,4,5**: After Batch 2 (40 queries): Report "MINIMUM BASELINE: 2 batches completed, applying stopping criteria (2 consecutive <5% yield)"
- **Agent 4**: Minimum 2 batches (40 queries), stop when 2 consecutive batches <5% data observation yield

**Quality Standards by Agent**:
- **Agent 1**: Minimum 5 batches (100 queries), stop when 2 consecutive batches <10% data observation yield
- **Agents 2,3,4,5**: Minimum 2 batches (40 queries), stop when 2 consecutive batches <5% data observation yield
- **Agent 4**: Minimum 2 batches (40 queries), stop when 2 consecutive batches <5% data observation yield

### B. Workspace Preparation & WHO GHO Integration
- Verify/create `data/ZMB` directory with enhanced dual-reference files
- Execute **WHO GHO Systematic Module** - Complete database mining of WHO Global Health Observatory
- Annual surveillance data extraction (2007-2024) and regional bulletins
- Execute WHO-specific query templates systematically

### C. Chronological Grid Foundation
- Generate month + year chronological grid: Jan 1970 → current month
- Create hot list of month-years with highest cholera transmission likelihood
- Light query bundle assessment per month × language

## Phase 2: Deep Dive Execution with Institutional Modules

### A. Hot Month Deep Dive (Core Method)
- Focus on identified high-cholera-likelihood time periods from chronological grid
- Apply successful query patterns from Phase 1A systematic coverage
- Target specific outbreak periods with intensive temporal drilling
- Execute searches in all associated languages with systematic coverage

### B. Revised Institutional Module Integration (4 MODULES MANDATORY)
- **WHO Systematic Module**: 60 queries with focused WHO institutional coverage
- **UN Humanitarian Module**: 50 queries with UNICEF/OCHA/ReliefWeb coverage
- **NGO Operational Module**: 45 queries with MSF/IFRC emergency response coverage
- **Academic/Research Module**: 45 queries with PubMed/Google Scholar systematic coverage
- **INSTITUTIONAL MODULES**: Execute 4 focused modules with batch-based stopping criteria
- Execute all institutional modules with targeted specialty coverage

### C. Enhanced Deep Dive Protocols
- **Comprehensive Citation Following**: ALL citations must be followed to depth ≤ 3
- **Enhanced Stop Criteria**: <5% data yield increase per iteration
- **Systematic Reference Mining**: ALL references in institutional sources must be pursued
- **Partner Network Expansion**: ALL partner organizations must be systematically searched
- Prioritize finer temporal scale and subnational data with geographic cascade modules

## Phase 3: Topical Gap-Fill Sweep with Academic Networks

### A. Coverage Matrix Development
- Build coverage matrix (year × theme) identifying systematic gaps
- Cover cross-border spread, climate drivers, interventions, genotyping, conflict impacts

### B. Academic Citation Networks Module Integration
- Follow ALL citation chains to completion (depth ≤ 3)
- Conference proceedings, dissertation repositories, citation network analysis
- Execute academic-specific templates systematically

### C. Multi-Language Expansion
- Portuguese: `"cólera {country}" vigilância epidemiológica boletim`
- French: `"choléra {country}" surveillance épidémiologique bulletin`
- Arabic: Arabic script queries for North African countries
- Local languages: vernacular terms and regional terminology

## Phase 4: Historical Deep Dive & Cross-Border Intelligence

### A. Decade-by-Decade Systematic Coverage
- Execute systematic temporal searches for each decade (1970s-2020s)
- Historical archives mining: colonial records, missionary documentation, government archives
- Newspaper morgues and historical media systematic coverage

### B. Cross-Border Regional Intelligence
- Search neighboring countries for transmission patterns
- Regional surveillance networks and coordination reports
- Cross-border outbreak documentation and response coordination

## Phase 5: Critical Review & Targeted Gap Analysis

### A. Comprehensive Data Review
- Identify temporal gaps, geographic gaps, data type gaps, source diversity gaps
- Generate targeted search expansion based on gap analysis

### B. Precision Gap-Filling Execution
- ULTRA DEEP searches with refined parameters and ULTRATHINK processing
- Minimum 25 precision queries per identified gap
- Reverse chronological search from known outbreaks
- Adjacent countries/regions for cross-border transmission evidence

## Phase 6: Quality Rating & Documentation (NO EXCLUSIONS)

### A. Source Reliability Classification (4-Tier Rating System)
**Level 1 (0.9-1.0)**: WHO Official Reports, National Ministry surveillance, Peer-reviewed literature
**Level 2 (0.7-0.9)**: UNICEF reports, OCHA assessments, Established NGOs, Regional organizations
**Level 3 (0.3-0.6)**: Reputable news, Local government, Preliminary academic reports
**Level 4 (0.1-0.3)**: Local media, Social media, Unofficial reports

### B. Quality Rating Standards (INCLUDE ALL SOURCES)
- Source documentation and quality rating (ALL sources included regardless of quality)
- Institutional credibility evaluation for rating purposes only (NO EXCLUSIONS)
- Confidence weight assignment based on reliability level (ALL sources included with appropriate weighting)

## Phase 7: Integration & Stop Criteria Assessment

### A. Data Integration Protocol
- Dual-reference system: source_index + source name matching
- Systematic duplication prevention and conflict resolution
- Uncertainty preservation with confidence weights

### B. Enhanced Stop Criteria Protocol (Data Observation Yield Method)

**MANDATORY STOPPING PROTOCOL**: Enhanced systematic discovery saturation detection based on data observation yield per batch.

**Protocol Structure**:
```
Given batches of 20 queries:
1. Run minimum X batches for baseline coverage (Agent-specific)
2. After X batches, stop when Y=2 consecutive batches achieve <Z% data observation yield (Agent-specific)
3. Exception: If source quality remains high (>0.8 average reliability), continue for 2 additional batches before applying stopping criteria
```

**Parameter Specifications**:
- **Agent 1**: X=5 batches minimum (100 queries), Y=2 consecutive batches, Z=10% threshold
  - Ensures adequate systematic coverage of priority sources
  - Establishes baseline performance patterns

- **Agents 2,3,5**: X=2 batches minimum (40 queries), Y=2 consecutive batches, Z=4% threshold
  - Accounts for natural variability in discovery process
  - Prevents stopping due to temporary methodology shifts
  - Optimized for specialized discovery phases (5% threshold)

- **Agent 4**: X=2 batches minimum (40 queries), Y=2 consecutive batches, Z=5% threshold
  - Obscure source expansion with systematic stopping criteria
  - Maximum 100 queries (5 batches)
  - Balances exploration with efficiency

#### **Data Observation Yield = Successful Queries Only**
```
Batch Yield = (Number of queries that resulted in at least one new row added to cholera_data.csv / 20 queries) × 100%

**MANDATORY**: After each batch, count ONLY the queries that successfully resulted in new cholera_data.csv additions.
**NOT** sources found, **NOT** potential data discovered - ONLY queries that produced completed CSV additions.

**Example**: If 6 out of 20 queries each resulted in at least one new cholera_data.csv row (regardless of how many rows each query produced), yield = 6/20 = 30%
```

**Quality Exception Protocol**:
- If average source reliability >0.8 in low-yield batches, continue for 2 additional batches
- Recognizes that high-reliability institutional sources may have sparse but valuable data
- Prevents premature termination during high-quality discovery phases

**Implementation Requirements**:
1. **Track data observations per batch**: Document new cholera surveillance data points discovered
2. **Calculate yield percentage**: (Observations/25) × 100% for each batch
3. **Monitor consecutive performance**: Track sequence of low-yield batches
4. **Apply quality exception**: Check average source reliability when approaching threshold
5. **Document stopping decision**: Record rationale for search termination

**Legacy Stop Criteria (Still Applied)**:
- Discovery Saturation: <5% data yield increase in single iteration
- Temporal Completion: All hot months and decades covered
- Engine Coverage: All engines systematically searched
- Module Completion: All institutional modules executed until saturation
- Gap Analysis: <5% marginal discovery rate achieved

## Phase 8: Comprehensive Reporting & Deliverables

### A. Enhanced File Formats

**metadata.csv** (Enhanced Dual-Reference System):
```csv
Index,Source,URL,Description,Date_Range,Data_Type,Status,Reliability_Level,Validation_Status,Search_Technique,Language_Original,Citation_Depth,Cross_References,Discovery_Method
```

**cholera_data.csv** (Complete Data Collection):
```csv
Index,Location,TL,TR,deaths,sCh,cCh,CFR,reporting_date,source_index,source,confidence_weight,processing_notes
```

## CRITICAL CSV FORMATTING REQUIREMENTS

**MANDATORY**: To prevent column shifting errors that compromise data integrity:

### 1. **Consistent Missing Value Handling**
- **Empty fields MUST use empty string between commas**: `,,` (correct)
- **NEVER skip commas for missing values**: `,3.9,` (incorrect - creates column shift)
- **All 13 columns MUST be present in every row** regardless of missing values

### 2. **Required CSV Validation Protocol**
**Execute BEFORE finalizing any CSV file:**

```bash
# Verify column count consistency (must be 13 for cholera_data.csv, 14 for metadata.csv)
awk -F, 'NR==1{cols=NF} NF!=cols{print "ERROR - Line " NR ": " NF " fields (expected " cols ")"}' cholera_data.csv
awk -F, 'NR==1{cols=NF} NF!=cols{print "ERROR - Line " NR ": " NF " fields (expected " cols ")"}' metadata.csv

# Check for common formatting errors
grep -n ',,,' cholera_data.csv  # Multiple consecutive commas indicating formatting issues
grep -n '[^,]$' cholera_data.csv | head -5  # Lines ending without comma structure
```

### 3. **Systematic Data Entry Rules**
- **Use exact header templates** - copy/paste to prevent typos
- **Validate each row before adding** - count commas = headers - 1
- **Boolean values**: Use `true`/`false` (lowercase, NOT True/False)
- **Date format**: Strict `YYYY-MM-DD` format only
- **Decimal format**: Use `.` not `,` for decimals (e.g., `3.9` not `3,9`)

### 4. **Quality Control Checkpoints**
**MANDATORY before file completion:**
- [ ] Header row contains exactly 13 fields for cholera_data.csv
- [ ] Header row contains exactly 14 fields for metadata.csv
- [ ] Every data row contains exactly same number of fields as header
- [ ] No trailing commas or spaces at end of lines
- [ ] All empty fields represented by empty strings between commas
- [ ] Boolean fields contain only `true` or `false`
- [ ] Date fields follow `YYYY-MM-DD` format exactly
- [ ] Decimal numbers use dot notation, not comma notation

### 5. **CSV Error Prevention Example**
```csv
# CORRECT - maintains 13 columns with empty fields
1,AFR::AGO,2025-01-01,2025-03-23,329,8543,,3.9,2025-03-28,1,WHO Disease Outbreak News 2025 Angola,1.0,16 of 21 provinces affected

# INCORRECT - missing comma creates column shift (only 12 columns)
1,AFR::AGO,2025-01-01,2025-03-23,329,8543,3.9,2025-03-28,1,WHO Disease Outbreak News 2025 Angola,1.0,16 of 21 provinces affected
```

**CRITICAL**: Column shifting errors corrupt the entire dataset and prevent MOSAIC modeling integration. Systematic validation is mandatory.

### B. Comprehensive Search Requirements

**MANDATORY REQUIREMENTS:**
- **MANDATORY systematic coverage** of 45 highest-priority tiered sources with batch-based stopping criteria
- **MANDATORY 4 institutional modules** (WHO Systematic, UN Humanitarian, NGO Operational, Academic/Research)
- **BATCH-BASED EXECUTION**: All searches executed in batches of 25 with agent-specific stopping criteria
- **Mandatory multi-language searches** for non-English countries
- **Required cross-border intelligence** with neighboring countries
- **Systematic institutional website deep dives** with specialty sub-modules
- **Complete reference chain following** (depth ≤ 3) for ALL institutional sources
- **Enhanced discovery saturation criteria**: <5% data yield increase per iteration

## COMPREHENSIVE QUERY FRAMEWORK TEMPLATES

### Enhanced WHO Institutional Templates (2 Modules)
```
# WHO Systematic Module (60 queries)
site:apps.who.int/gho/data cholera {country} annual surveillance 2007-2024
"WHO Global Health Observatory" {country} cholera data CSV download
"WHO Disease Outbreak News" {country} cholera situation reports {year}
"WHO AFRO" {country} cholera weekly bulletin regional surveillance

# WHO WER Integration (included in WHO Systematic)
site:who.int/publications/journals/weekly-epidemiological-record cholera {country}
"Weekly Epidemiological Record" cholera {country} surveillance {year}
"WER" "WHO" cholera outbreak {country} epidemic investigation
"Relevé épidémiologique hebdomadaire" choléra {country}
```

### Academic Citation Network Templates
```
"cholera {country}" 1970s 1980s historical emergence epidemiology
site:scholar.google.com "cholera {country}" dissertation doctoral research
"Vibrio cholerae" {country} molecular epidemiology phylogenetic analysis
"cholera transmission" {country} environmental risk factor studies
```

### Enhanced Humanitarian Institutional Templates (2 Modules)
```
# UN Humanitarian Module (50 queries)
"UNICEF {country} Humanitarian Report" cholera outbreak emergency response
"UNICEF {country} Situation Report" cholera emergency flash update
"UNICEF {country}" WASH cholera prevention intervention programs
site:unicef.org {country} cholera humanitarian response coordination

# NGO Operational Module (45 queries)
"MSF operational research" {country} cholera treatment center outcomes
"MSF {country}" cholera clinical management treatment protocols
"MSF emergency response" {country} cholera outbreak field intervention
site:msf.org {country} cholera epidemiological investigation reports
```

### Multi-Language Templates
```
Portuguese: "cólera {country}" vigilância epidemiológica boletim ministério
French: "choléra {country}" surveillance épidémiologique bulletin hebdomadaire
Spanish: "cólera {country}" vigilancia epidemiológica brote transmisión
Arabic: [Arabic script] for North African countries
```

### Cross-Border Intelligence Templates
```
{country} cholera {neighboring_country} cross-border transmission patterns
{country} cholera regional surveillance network early warning coordination
{country} cholera migratory population refugee displacement transmission
{region} cholera trade route transportation corridor outbreak cluster
```

## Institutional Module Specifications

### MANDATORY 4-MODULE INSTITUTIONAL SYSTEM (BATCH-BASED EXECUTION)

**Each institutional module executed with batch-based stopping criteria and comprehensive specialty coverage:**

#### WHO SYSTEMATIC MODULE (Batch-based execution with stopping criteria)
- Base WHO queries: 100
- Citation network expansion: 25 (follow ALL WHO citations to depth ≤ 3)
- Temporal drilling: 25 per major outbreak (pre/during/post outbreak WHO documentation)
- Geographic cascade: 25 (country → regional → global WHO levels)
- Partner expansion: 25 (WHO partnerships with OCHA, Africa CDC, ECDC, academic institutions)
- Document diversification: 25 (policy briefs, technical consultations, evaluations, press releases)
- Multilingual expansion: 25 (French AFRO, Portuguese PAHO, Arabic EMRO, Spanish PAHO documents)
- Historical depth: 25 (1970s-2000s WHO country cooperation and surveillance evolution)
- Cross-validation: 25 (WHO vs. other institutional source triangulation)

#### WHO WER (Weekly Epidemiological Record) MODULE (Batch-based execution with stopping criteria)
- Base WER queries: 100 (WER archives 1970-2024, country-specific outbreak reports)
- WER citation network: 25 (follow ALL WER citations to depth ≤ 3)
- WER temporal drilling: 25 per outbreak (pre/during/post outbreak WER coverage)
- WER geographic cascade: 25 (national → subnational → cross-border WER reports)
- WER partner integration: 25 (WER collaboration with ECDC, Africa CDC, academic partners)
- WER document diversification: 25 (epidemiological bulletins, technical reports, surveillance methods)
- WER multilingual archives: 25 (French, Spanish, Arabic WER editions)
- WER historical archives: 25 (1960s-2020s WER cholera surveillance evolution)
- WER cross-validation: 25 (WER vs. WHO GHO/DON consistency validation)

#### UNICEF TEMPORAL EXPANSION MODULE (Batch-based execution with stopping criteria)
- Base UNICEF queries: 100 (country office, regional office, emergency response, WASH programs)
- UNICEF citation network: 25 (follow ALL UNICEF citations to depth ≤ 3)
- UNICEF temporal drilling: 25 per crisis (crisis onset → peak → recovery → evaluation)
- UNICEF geographic cascade: 25 (country → regional → global → field office levels)
- UNICEF partner expansion: 25 (UN coordination, NGO partnerships, government collaboration)
- UNICEF document diversification: 25 (program documents, supply reports, research publications)
- UNICEF multilingual expansion: 25 (local language reports, donor country documentation)
- UNICEF historical depth: 25 (early emergency response evolution and programming history)
- UNICEF cross-validation: 25 (UNICEF-WHO-MSF coordination triangulation)

#### MSF OPERATIONAL RESEARCH MODULE (Batch-based execution with stopping criteria)
- Base MSF queries: 100 (operational research, emergency response, country programs, treatment centers)
- MSF citation network: 25 (follow ALL MSF citations to depth ≤ 3)
- MSF temporal drilling: 25 per intervention (setup → operational → handover → evaluation)
- MSF geographic cascade: 25 (mission → regional → operational centers → field locations)
- MSF partner expansion: 25 (medical organizations, local authorities, academic medical centers)
- MSF document diversification: 25 (clinical protocols, operational research, training materials)
- MSF multilingual expansion: 25 (field mission languages, medical protocol translations)
- MSF historical depth: 25 (early missions, program evolution, operational model development)
- MSF cross-validation: 25 (MSF-WHO-UNICEF collaboration and data triangulation)

### INSTITUTIONAL MODULE EXECUTION REQUIREMENTS

**Citation Following Protocol (MANDATORY):**
- ALL references in institutional reports MUST be followed to depth ≤ 3
- Academic sources cited MUST be accessed and data extracted
- Government reports referenced MUST be independently accessed
- Partner organization citations MUST be systematically tracked
- Citation networks MUST be mapped and documented

**Specialty Module Completion Criteria:**
- Each 15-query specialty module MUST be completed before proceeding
- ALL partner organization networks MUST be explored systematically
- ALL temporal drilling MUST cover pre/during/post phases
- ALL geographic cascades MUST cover all administrative levels
- ALL multilingual searches MUST be executed for applicable countries
- ALL historical archives MUST be systematically searched
- ALL cross-validation MUST identify and resolve discrepancies

**Module Execution Requirements:**
- WHO Systematic: Execute until <5% data yield increase achieved
- WHO WES: Execute until <5% data yield increase achieved
- UNICEF: Execute until <5% data yield increase achieved
- MSF: Execute until <5% data yield increase achieved
- **Combined Institutional Completion: All modules executed until discovery saturation**

## COMPREHENSIVE SEARCH EXECUTION REQUIREMENTS (BATCH-BASED FRAMEWORK)

**Search Execution Standards:**
- Execute searches in batches of 25 queries each
- Apply agent-specific data observation yield stopping criteria
- Track and document batch performance and yield rates

**Discovery Continuation Criteria:**
- Continue search activities until data yield increase <1% in single iteration
- Maintain ≥85% Level 1-2 source reliability throughout
- Complete temporal coverage (1970-2024) with systematic gap analysis
- Achieve maximum available geographic granularity for all discovered outbreaks

**Agent-Specific Query Requirements (MANDATORY):**
- **Agent 1**: Data observation yield stopping criteria (minimum 5 batches/100 queries, stop when 2 consecutive batches <10% yield)
- **Agent 2**: Data observation yield stopping criteria (minimum 2 batches/40 queries, stop when 2 consecutive batches <5% yield)
- **Agent 3**: Data observation yield stopping criteria (minimum 2 batches/40 queries, stop when 2 consecutive batches <5% yield)
- **Agent 4**: Data observation yield stopping criteria (minimum 2 batches/40 queries, stop when 2 consecutive batches <5% yield)
- **Agent 5**: Data observation yield stopping criteria (minimum 2 batches/40 queries, stop when 2 consecutive batches <5% yield)
- **Agent 6**: Quality audit and validation (comprehensive source authentication and URL verification as needed - no query limit)

**MANDATORY BATCH PROCESSING:**
- **All Agents 1-5**: Execute searches in batches of 20 queries, update CSV files after each batch
- **Agent 1**: Track data observation yield per batch, minimum 5 batches before stopping criteria apply (stop at 2 consecutive <10%)
- **Agents 2,3,4,5**: Track data observation yield per batch, minimum 2 batches before stopping criteria apply (stop at 2 consecutive <5%)
- **Agent 4**: Minimum 2 batches (40 queries), stop when 2 consecutive batches <5% data observation yield

## VALIDATION REQUIREMENTS

**Data Quality Rating** (ALL SOURCES INCLUDED):
- Accept and rate ALL CFR values without exclusions (document outliers with appropriate confidence weighting)
- Include zero-reporting periods as epidemiologically significant
- INCLUDE ALL SOURCES regardless of perceived quality (rate appropriately with confidence weighting)
- Quality rating system replaces exclusion - ALL sources documented with appropriate confidence weights
- Cross-country validation for rating enhancement when available
- Citation network validation for rating purposes when available

**Success Criteria** (Maximum Data Inclusion):
- All 8 phases systematically completed until discovery saturation
- ALL discovered data included with quality ratings (NO EXCLUSIONS)
- Comprehensive source inclusion prioritized - quality reflected in ratings only
- Complete documentation and quality rating for all sources and data points
- All institutional modules executed until exhaustion with fully inclusive approach

## FINAL VERIFICATION CHECKLIST

Before submitting, verify ALL requirements met:
- [ ] Complete CLAUDE.md 8-phase methodology followed systematically
- [ ] **AGENT 1: Data observation yield stopping criteria applied (minimum 5 batches/100 queries, stopped when 2 consecutive batches <8% yield)**
- [ ] **AGENTS 2,3,5: Data observation yield stopping criteria applied (minimum 2 batches/40 queries, stopped when 2 consecutive batches <4% yield)**
- [ ] **AGENT 4: Conditional requirement met (minimum 2 batches/40 queries, +2 if new rows added to cholera_data.csv)**
- [ ] All institutional modules executed until discovery saturation
- [ ] Strategic queries systematically executed across all categories until completion
- [ ] All 6 quality documentation phases completed
- [ ] ALL discoverable data points included and documented (NO EXCLUSIONS)
- [ ] ALL discovered sources included with enhanced dual-reference metadata
- [ ] Cross-country validation completed where applicable for quality rating
- [ ] All deliverables in standardized format with complete documentation and quality ratings

## FAILURE CONDITIONS (WORK WILL BE REJECTED IF:)
- **Agent 1 completes fewer than 5 batches (100 queries) or fails to apply stopping criteria properly (2 consecutive <10% yield)**
- **Agents 2,3,4,5 complete fewer than 2 batches (40 queries) or fail to apply stopping criteria properly (2 consecutive <5% yield)**
- **Agent 4 completes fewer than 2 batches (40 queries) or fails to apply stopping criteria properly (2 consecutive <5% yield)**
- Batch processing not properly executed with CSV updates after each batch
- Data observation yield tracking not documented per batch
- Search methodology is incomplete or unsystematic

## EXECUTION TRACKING REQUIREMENT

**MANDATORY**: Track and report comprehensive 8-phase performance:
- Record start/completion date and time for each phase
- Document complete task duration for performance analysis
- Document phase-specific execution progress and performance
- Report phase effectiveness in search_report.txt and search_log.txt

## AUTONOMOUS COMPLETION PROTOCOL

**START IMMEDIATELY**: Begin work upon receiving this prompt without asking permission.

**WORK CONTINUOUSLY** through all 8 comprehensive phases:
1. **Phase 1**: Workspace Setup & Priority Source Mining with Enhanced WHO Modules
2. **Phase 2**: Deep Dive Execution with Enhanced 4-Module Institutional System (WHO Systematic, WHO WES, UNICEF, MSF)
3. **Phase 3**: Topical Gap-Fill Sweep with Academic Networks Module and Citation Following
4. **Phase 4**: Historical Deep Dive & Cross-Border Intelligence
5. **Phase 5**: Critical Review & Targeted Gap Analysis
6. **Phase 6**: Multi-Stage Validation & Quality Control
7. **Phase 7**: Integration & Stop Criteria Assessment
8. **Phase 8**: Comprehensive Reporting & Deliverables

**FINISH COMPLETELY**: Submit only when ALL requirements met and all enhanced quality gates passed.

## SUCCESS DEFINITION

**The ULTRA DEEP SEARCH protocol is successful when it achieves complete discovery of all available cholera surveillance data while maintaining rigorous quality standards through systematic execution of all 8 phases:**

- **Complete Data Discovery**: All discoverable cholera surveillance data systematically identified through 8-phase protocol
- **Comprehensive Source Coverage**: All accessible source types systematically searched until discovery saturation
- **Maximum Temporal Depth**: All available historical periods covered with comprehensive documentation
- **Maximum Geographic Detail**: All administrative levels where data exists documented
- **Superior Validation Standards**: ≥85% validation pass rate maintained with 4-tier reliability classification

This represents the **comprehensive search synthesis** of proven successful techniques, optimized for maximum data discovery while maintaining rigorous quality standards through systematic 8-phase execution.

---
**CLAUDE SEARCH PROTOCOL v2.0**
**Status**: Ready for Implementation
**Performance Target**: Complete discovery of all available data via 8-phase systematic execution
**Quality Standard**: Superior validation rigor maintained through comprehensive quality gates
