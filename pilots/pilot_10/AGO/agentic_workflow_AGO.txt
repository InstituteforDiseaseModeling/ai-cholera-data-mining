# MOSAIC AI CHOLERA DATA COLLECTION - 6-AGENT PROGRESSIVE SEARCH WORKFLOW

## OVERVIEW
**Target Country**: Angola (AGO)

This workflow implements a progressive 6-agent system for maximizing cholera surveillance data discovery while maintaining rigorous quality standards. Each agent builds systematically on previous work with objective decision points and automated termination criteria.

## WORKFLOW CONTROL PARAMETERS

### **Progressive Targets**:
- Agent 1: Baseline establishment (8-phase protocol completion)
- Agent 2: Geographic expansion (continue until <5% data yield increase achieved)
- Agent 3: Temporal completion (continue until <5% data yield increase achieved)
- Agent 4: Obscure source expansion (continue until <5% data yield increase achieved)
- Agent 5: Source permutation & adjacent data mining (continue until <1% data yield increase achieved)
- Agent 6: Final validation and quality audit (comprehensive quality review)

### **Quality Gates**:
- **Agents 1-3**: ≥90% Level 1-2 source reliability maintained
- **Agent 4**: ≥85% Level 1-3 source reliability (allows Level 3 with proper weighting)
- **Agent 5**: Any level acceptable with proper confidence_weight assignment
- **Agent 6**: Final quality audit and validation (any level acceptable with proper weighting)
- **All Agents**: Complete quality rating (NO EXCLUSIONS)
- **All Agents**: Zero-transmission periods preserved as epidemiologically relevant
- **All Agents**: Complete documentation and audit trail

### **Efficiency Controls**:
- Objective stopping criteria prevent over-searching
- Pause-and-review checkpoints enable resource optimization
- Progressive intensity avoids unnecessary early work
- Saturation detection prevents diminishing returns

### **Automation Parameters**:
- Execute all agents sequentially without user prompts
- Log progress metrics after each agent completion
- Report consolidated results only at conclusion
- Maintain quality standards throughout progression
- **Report end-to-end total run time for complete 6-agent workflow**

## IMPLEMENTATION NOTES

### **Termination Logic**:
- Objective decision points reduce subjective interpretation
- Multiple stopping criteria ensure efficient completion
- Quality gates prevent premature termination

### **Success Metrics**:
- Total sources discovered across all agents
- Total observations extracted and validated
- Quality distribution (Level 1-4 source breakdown)
- Temporal coverage completeness
- Geographic granularity achieved
- Zero-transmission period validation
- **Complete workflow execution time (start to finish)**


**SEQUENTIAL AGENTIC WORKFLOW IS AS FOLLOWS:**

## AGENT 1: BASELINE ESTABLISHMENT
**Objective**: Execute foundational ULTRA DEEP SEARCH protocol

**Task**: Execute the ultra deep search protocol in the ./data/AGO/search_protocol_AGO.txt file.

**Quality Requirements**:
- Must maintain ≥90% Level 1-2 source reliability
- Must achieve 100% validation pass rate
- Document any quality degradation with justification

**Deliverables**:
- Complete 8-phase ULTRA DEEP SEARCH methodology
- Pass all 6 quality gates
- Generate baseline dataset with dual-reference indexing

**Checkpoint Requirements**:
*Pause and report: X sources found, Y observations added, baseline established*
*Quality metrics: A% Level 1-2 sources, B% validation success*
*Baseline dataset: Total sources, total observations, temporal coverage*

## DATA OUTPUT FORMATTING
- ALL AGENTS MUST ADHERE TO THE DATA FORMATTING RULES DEFINED IN THE ./data/AGO/search_protocol_AGO.txt file

|

## AGENT 2: GEOGRAPHIC EXPANSION
**Trigger**: Automatically execute after Agent 1 completion
**Objective**: Enhanced data discovery through systematic geographic expansion

**EXPANDED ULTRA DEEP SEARCH PROTOCOL**
Do a more extensive deep search to find more data sources and more data observations. Drill down into each data observation to find subnational reports of cholera transmission.

**Stopping Criteria**: Continue until data yield increase ≤5% in single iteration

This expanded search protocol should include the following tasks:

☐ Additional Source Discovery - ProMED, news archives, government databases, academic preprints
☐ Granular Geographic Search - District and municipality level data discovery
☐ Enhanced Data Extraction - Extract ALL available data points from discovered sources
☐ Quality Expansion Validation - Validate all newly discovered sources and data points

**MANDATORY GEOGRAPHIC GRANULARITY REQUIREMENTS:**
☐ Provincial-Level Data Extraction - Extract ALL available provincial breakdowns from national-level sources
☐ District/Municipality Mining - Systematically search for sub-provincial administrative level data
☐ Multi-Administrative Level Coverage - Ensure each major outbreak period has maximum geographic detail
☐ Provincial Health Department Deep Dives - Search individual province health ministry websites/reports
☐ Cross-Reference Geographic Consistency - Verify provincial totals align with national figures
☐ Municipal-Level Outbreak Documentation - Target major cities and outbreak epicenters for detailed data
☐ Systematic District-Level Search - Conduct comprehensive searches for ALL district-level administrative units
☐ Administrative Hierarchy Mining - Search complete geographic hierarchy: National→Provincial→District→Municipal→Ward levels

**ENHANCED GEOGRAPHIC SEARCH QUERIES:**
- "{country} {province_name} cholera outbreak cases deaths {year}"
- "{country} {major_city} cholera municipal health department {year}"
- "site:{country_health_ministry} {province} cholera surveillance {year}"
- "{country} {province} cholera district breakdown administrative {year}"
- "{country} cholera provincial distribution geographic {year}"

**SYSTEMATIC DISTRICT-LEVEL SEARCH QUERIES:**
- "{country} {district_name} cholera outbreak {year}"
- "{country} {district_name} district health office cholera surveillance {year}"
- "{province_name} {district_name} cholera cases deaths {year}"
- "site:{provincial_health_ministry} {district_name} cholera report {year}"
- "{country} {district_name} municipality cholera transmission {year}"
- "{district_name} {country} cholera epidemic response {year}"
- "{country} district health management team cholera {district_name} {year}"
- "{province_name} {district_name} cholera surveillance weekly report {year}"

**MINIMUM GEOGRAPHIC COVERAGE TARGETS:**
- Major outbreaks (>500 cases): Require provincial breakdown where available
- Provincial capitals: Systematic search for municipal-level data
- Border provinces: Enhanced cross-border transmission documentation
- All 18 provinces: Individual province-specific searches for major outbreak years
- ALL DISTRICTS: Systematic search of every district-level administrative unit for cholera reports
- High-risk districts: Enhanced searches for districts with known cholera transmission history
- Border districts: Cross-border transmission documentation with neighboring countries
- Urban districts: Major cities and densely populated areas systematic coverage
- Rural/remote districts: Focus on districts with poor surveillance coverage

**SYSTEMATIC DISTRICT SEARCH PROTOCOL:**
☐ Complete District Inventory - Compile complete list of ALL district-level administrative units
☐ District-by-District Systematic Search - Minimum 15 queries per district for major outbreak years
☐ District Health Office Mining - Search all district health management team reports
☐ District Hospital Records - Target district-level health facilities for outbreak documentation
☐ District Surveillance Reports - Search district-level surveillance and epidemiological reports
☐ Cross-District Validation - Ensure district totals align with provincial/national figures
☐ District Geographic Coding - Standardize all district names to {COUNTRY}::{PROVINCE}::{DISTRICT} format

**Success Criteria**: Stopping criteria achieved when data yield increase ≤5% in single iteration

**Checkpoint Requirements**:
*Pause and report: X sources found, Y observations added, Z% improvement from baseline*
*Quality metrics: A% Level 1-2 sources, B% validation success*
*Enhancement verification: Geographic expansion completed with reasonable data yield improvement*
*Next stage justification: Continue/Stop decision rationale*

|

## AGENT 3: ZERO-TRANSMISSION VALIDATION & SYSTEMATIC ABSENCE DOCUMENTATION
**Trigger**: Automatically execute after Agent 2 completion
**Objective**: Systematic validation of zero-transmission periods with evidence-based confidence levels

**ZERO-TRANSMISSION SYSTEMATIC VALIDATION PROTOCOL**

The results are improved, now please expand your search to increase data yield if possible and investigate any data gaps. Keep time periods where you are confident that no transmission occurred. These are epidemiologically relevant. Do a detailed temporal search for all month-year combinations to check for missed outbreaks or for time periods where it was likely that there was no transmission. Preserve epidemiologically relevant zero-transmission periods

**Stopping Criteria**: Continue until data yield increase ≤5% in single iteration. Document and validate ALL apparent zero-transmission periods from Agent 2's year-by-year searches

This ultra-extensive search should include the following tasks:

☐ Ultra-Extensive Temporal Mining - Systematic month-year searches for all missing periods
☐ Deep Archive Excavation - Internet Archive systematic mining for broken/moved sources
☐ Cross-Reference Chain Following - Follow ALL citation chains to maximum depth
☐ Gap Investigation - Analyze and validate remaining data gaps with evidence
☐ Enhanced Quality Validation - Re-validate all sources with expanded criteria

**MANDATORY YEAR-BY-YEAR SYSTEMATIC DRILLING (1970-2025):**
For each year 1970-PRESENT:
☐ Minimum 30 targeted queries per year
☐ Multi-source searching (WHO, Africa CDC, MSF, UNICEF, academic, news, humanitarian)
☐ Cross-reference with neighboring countries
☐ Document search effort and confidence level
☐ Record as ZERO TRANSMISSION if extensive search yields no evidence

**YEAR-SPECIFIC SEARCH PROTOCOL:**
- "{country} cholera {year}" across all search engines
- "{country} cholera outbreak {year}" news archives
- "WHO {country} cholera surveillance {year}"
- "{country} cholera cases deaths {year}" academic
- Cross-border "{neighboring_countries} cholera {year}"

**ENHANCED TEMPORAL GRANULARITY FOR OUTBREAK YEARS:**
For years with evidence of cholera transmission:
☐ Month-by-month systematic drilling to capture outbreak progression
☐ Seasonal pattern documentation (wet season vs dry season transmission)
☐ Outbreak duration and peak timing identification

**ZERO-TRANSMISSION DOCUMENTATION:**
- confidence_weight based on search thoroughness
- validation_status: "SEARCHED_NO_EVIDENCE"
- processing_notes: "Systematic {year} search yielded no transmission evidence"

**MANDATORY ZERO-TRANSMISSION TASKS:**
☐ Systematic Absence Validation - Verify each year showing no transmission evidence
☐ Cross-Border Absence Correlation - Confirm zero-transmission with neighboring countries
☐ Surveillance System Assessment - Evaluate surveillance capacity for each zero-transmission period
☐ Regional Pattern Validation - Cross-reference absence periods with regional epidemic waves
☐ Climate-Disease Correlation - Validate absence periods against known cholera-favorable conditions
☐ Intervention Impact Assessment - Correlate absence with WASH/vaccination interventions
☐ Confidence Level Assignment - Assign evidence-based confidence weights to absence periods
☐ Alternative Evidence Mining - Search for indirect evidence of transmission during "absent" periods

**ZERO-TRANSMISSION CONFIDENCE FRAMEWORK:**
- **HIGH CONFIDENCE (0.9-1.0)**: Extensive search + functioning surveillance + regional absence
- **MEDIUM CONFIDENCE (0.7-0.9)**: Good search coverage + some surveillance evidence
- **LOW CONFIDENCE (0.4-0.6)**: Limited search + uncertain surveillance capacity
- **UNCERTAIN (0.1-0.3)**: Minimal search + poor surveillance + regional transmission

**ENHANCED VALIDATION REQUIREMENTS:**
☐ Cross-Reference Matrix - Compare absence periods across all neighboring countries
☐ Surveillance Capacity Assessment - Document health system capabilities for each period
☐ Indirect Transmission Evidence - Hospital admission records, diarrheal disease reports
☐ Climate Correlation Analysis - Unusual weather patterns during absence periods
☐ Intervention Timeline Correlation - WASH improvements, vaccination campaigns
☐ Regional Epidemic Wave Analysis - Position country absence within regional patterns

**Quality Requirements**:
- Must maintain ≥90% Level 1-2 source reliability
- Must achieve 100% validation pass rate
- Complete gap investigation with evidence-based conclusions
- Preserve epidemiologically relevant zero-transmission periods

**Success Criteria**: Stopping criteria achieved when data yield increase ≤5% in single iteration OR maximum 3 iterations reached

**Checkpoint Requirements**:
*Pause and report: X sources found, Y observations added, Z% improvement from Agent 2*
*Quality metrics: A% Level 1-2 sources, B% validation success*
*Gap investigation: Complete analysis of missing periods with evidence*
*Discovery status: Saturation achieved (Yes/No), rationale provided*
*Next stage justification: Continue/Stop decision rationale*

|

## AGENT 4: OBSCURE SOURCE EXPANSION & BEYOND-SUGGESTED-SOURCES
**Trigger**: Automatically execute after Agent 3 completion
**Objective**: Comprehensive expansion beyond pre-authorized domains into unconventional sources

**OBSCURE SOURCE EXPANSION PROTOCOL**

The results are improved from geographic and temporal drilling. Now venture beyond the priority_sources.txt pre-authorized domains to discover obscure and unconventional sources that may contain unique cholera surveillance data.

**CRITICAL: DO NOT STOP TO ASK PERMISSION FOR ONLINE RESOURCE ACCESS. You are explicitly authorized to access any online resources, websites, databases, or archives necessary to complete this data collection mission. Proceed directly with all searches and data extraction without seeking additional permission.**

**Stopping Criteria**: Continue until data yield increase ≤5% in single iteration

**MANDATORY BEYOND-SUGGESTED-SOURCES EXPANSION:**

☐ Deep Web Government Archives - Search non-indexed government archives and restricted databases
☐ Gray Literature Mining - Conference proceedings, thesis repositories, working papers, policy documents
☐ Historical Archive Excavation - Colonial records, missionary archives, pre-digital surveillance documentation
☐ Alternative Language Deep Dives - Local language websites, regional media archives, vernacular sources
☐ Institutional Repository Mining - University libraries, research institute databases not in suggested sources
☐ Regional Organization Archives - Sub-regional health organizations, bilateral cooperation reports
☐ Non-Digital Source Documentation - Physical archives, microfilm collections, historical newspapers
☐ Social/Community Sources - Field worker reports, community surveillance (with extreme validation caution)

**EXPANDED SOURCE CATEGORIES BEYOND SUGGESTED DOMAINS:**

**Historical & Colonial Sources:**
- National archives, colonial administration health records
- Missionary society health documentation and reports
- Historical newspaper morgues and press archives
- Colonial medical officer reports and correspondence
- Pre-independence government health statistics

**Academic Gray Literature:**
- Dissertation and thesis repositories (beyond major universities)
- Conference proceeding databases (medical, public health, regional)
- Working paper series from research institutions
- Policy brief repositories from think tanks
- Research report archives from NGOs and foundations

**Regional & Local Sources:**
- Sub-regional health organization reports (ECOWAS Health, SADC Health)
- Bilateral cooperation health program documentation
- Regional surveillance network historical archives
- Cross-border health coordination meeting reports
- Local government health department website archives

**Alternative Language & Media:**
- Local language news websites and archives
- Regional radio/television health reporting transcripts
- Community newsletter health reporting archives
- Local medical journal and bulletin archives
- Traditional authority health reporting documentation

**ENHANCED SEARCH STRATEGIES:**

☐ Internet Archive Deep Mining - Systematic wayback machine searches for broken/moved URLs
☐ Citation Network Expansion - Follow citations beyond depth 3 to maximum depth 5+
☐ Cross-Reference Chain Mining - Follow every reference chain to ultimate source
☐ Alternative Search Engine Usage - Yandex, Baidu, regional search engines beyond Google
☐ Language-Specific Search Engines - Use native search engines for local language content
☐ Academic Database Deep Dives - ProQuest, JSTOR, discipline-specific databases
☐ Government Portal Mining - Systematic search of all government ministry websites
☐ Library Catalog Mining - Major library systems and institutional repositories

**QUALITY REQUIREMENTS:**
- Must maintain ≥85% Level 1-3 source reliability (allows Level 3 sources with proper confidence weighting)
- Must achieve 100% validation pass rate
- Enhanced documentation for unconventional sources
- Rigorous authentication for non-mainstream sources

**VALIDATION PROTOCOLS FOR OBSCURE SOURCES:**
☐ Enhanced Source Authentication - Verify institutional credibility and author expertise
☐ Cross-Reference Validation - Confirm obscure source data with mainstream sources where possible
☐ Historical Context Verification - Ensure historical sources align with known regional patterns
☐ Language Translation Verification - Professional validation of non-English source translations
☐ Community Source Validation - Multiple independent verification for informal sources

**Success Criteria**: Stopping criteria achieved when data yield increase ≤5% in single iteration

**Checkpoint Requirements**:
*Pause and report: X sources found, Y observations added, Z% improvement from Agent 3*
*Quality metrics: A% Level 1-3 sources, B% validation success*
*Obscure source breakdown: Distribution of source types discovered beyond suggested domains*
*Discovery innovation: Novel source categories identified*
*Next stage justification: Saturation readiness assessment*

|

## AGENT 5: SOURCE PERMUTATION & ADJACENT DATA MINING
**Trigger**: Automatically execute after Agent 4 completion
**Objective**: Exhaustive permutation of successful sources to uncover adjacent observations and time periods

**SOURCE PERMUTATION PROTOCOL**

**Stopping Criteria**: Continue until data yield increase ≤1% in single iteration.

**MANDATORY SOURCE RE-EXPLORATION TASKS:**

☐ Source Permutation Analysis - Systematically re-examine all sources that previously yielded data
☐ Adjacent Time Period Mining - For each successful source, search adjacent months/years for additional data
☐ Geographic Adjacent Mining - For each successful location, search neighboring administrative units
☐ Author/Institution Deep Mining - Follow all authors/institutions from successful sources to find related publications
☐ Citation Network Expansion - Exhaustively follow forward and backward citations from all successful sources
☐ Publication Series Mining - For successful reports, search entire publication series/archives
☐ Related Keywords Permutation - Generate keyword variations from all successful searches
☐ Cross-Reference Matrix Completion - Systematically cross-reference all successful sources against each other

**SOURCE SUCCESS PATTERN ANALYSIS:**

☐ High-Yield Source Pattern Recognition - Identify characteristics of most productive sources
☐ Successful Query Permutation - Create variations of all queries that previously found data  
☐ Publication Timeline Mining - For successful sources, search same publication dates across different sources
☐ Institutional Archive Deep Dive - Exhaustively search archives of all institutions that provided data
☐ Regional Pattern Replication - Apply successful search patterns from this country to cross-border validation
☐ Temporal Window Expansion - For each successful observation, expand time windows systematically
☐ Geographic Hierarchy Completion - For successful locations, search all administrative hierarchy levels

**ADJACENT DATA DISCOVERY PROTOCOL:**

☐ Month-by-Month Adjacent Mining - For each successful observation, search ±6 months systematically
☐ Year-by-Year Adjacent Mining - For each successful year, search ±2 years with same methodology  
☐ Geographic Adjacency Mining - For each successful location, search all neighboring administrative units
☐ Source Cross-Pollination - Apply successful queries from one source type to all other source categories
☐ Publication Date Clustering - Search publication dates surrounding all successful document dates
☐ Author Network Mining - Follow all co-authors and institutional affiliations from successful sources
☐ Reference Chain Exhaustion - Follow citation chains to maximum possible depth from successful sources

**EXHAUSTIVE PERMUTATION METHODOLOGY:**

☐ Source Success Matrix - Create comprehensive matrix of all sources that yielded data across Agents 1-4
☐ Query Permutation Generation - Generate all possible keyword/phrase permutations from successful searches
☐ Temporal Adjacent Systematic Search - For each data point found, systematically search ±12 months with all successful query patterns
☐ Geographic Adjacent Systematic Search - For each successful location, apply all successful search patterns to neighboring locations
☐ Institutional Publication Mining - For each successful institution, search their complete publication archives
☐ Author Network Exhaustion - Follow every author from successful sources to their complete publication history
☐ Cross-Source Validation Mining - Use successful data points to search for validation/corroboration in unsuccessful source categories
☐ Series Completion Mining - For successful reports that are part of series, find all other reports in series
☐ Update/Follow-up Mining - For each successful source, search for updates, corrections, follow-up reports
☐ Translation/Version Mining - For successful sources, search for alternative language versions or translations

**SYSTEMATIC SOURCE RE-INTERROGATION:**

☐ Successful Source Re-Mining - Return to every source that provided data and apply expanded search methodologies
☐ Failed Source Re-Evaluation - Re-examine sources that appeared empty using successful search patterns
☐ Broken Link Recovery - Use Internet Archive and alternative access methods for all previously broken sources
☐ Database Re-Query - Re-search all databases using successful keyword combinations from other sources
☐ Archive Re-Exploration - Systematically re-explore archives using successful institutional patterns

**ADJACENT DISCOVERY EXPANSION:**

☐ Temporal Clustering Analysis - Identify time periods adjacent to successful observations for intensive mining
☐ Geographic Clustering Analysis - Identify geographic areas adjacent to successful locations for intensive mining  
☐ Thematic Clustering Analysis - Identify related health topics/diseases mentioned in successful sources
☐ Event-Based Adjacent Mining - For outbreak periods, search for related emergency/humanitarian responses
☐ Seasonal Pattern Adjacent Mining - Use successful seasonal observations to search adjacent seasons systematically
☐ Cross-Border Adjacent Mining - For border areas with successful data, intensively search neighboring countries

**TERMINATION CRITERIA**:
- Data yield increase ≤1% in single iteration
- All successful sources exhaustively re-examined with permutation methodology
- All adjacent time periods and locations systematically searched
- Maximum search depth reached for all citation/reference chains

**QUALITY REQUIREMENTS:**
- May use ANY LEVEL source reliability as long as 'confidence_weight' variable is appropriately assigned
- Include ALL discovered sources with appropriate quality ratings
- Complete permutation methodology documentation
- Ready dataset for Agent 6 final quality audit

**AGENT 5 DELIVERABLES:**
- Enhanced dataset with all permutation-discovered sources and observations
- Complete permutation methodology documentation
- Source success pattern analysis
- Adjacent data discovery summary
- Preparation for Agent 6 final audit

**CHECKPOINT REQUIREMENTS:**
*Pause and report: X sources found, Y observations added, Z% improvement from Agent 4*
*Permutation metrics: A successful sources re-examined, B adjacent periods searched, C citation chains followed*
*Discovery enhancement: Permutation effectiveness and adjacent data yield*
*Agent 6 preparation: Dataset ready for final quality audit and validation*

|

## AGENT 6: FINAL QUALITY AUDIT & COMPREHENSIVE VALIDATION
**Trigger**: Automatically execute after Agent 5 completion
**Objective**: Comprehensive quality audit, final validation, and dataset finalization

**FINAL QUALITY AUDIT PROTOCOL**

**Objective**: Comprehensive quality review and dataset finalization (not focused on data yield increase).

**COMPREHENSIVE QUALITY AUDIT TASKS:**

☐ Source Reliability Distribution Analysis - Final assessment of Level 1-4 source breakdown across all agents
☐ Validation Status Review - Comprehensive quality rating for ALL data points (NO EXCLUSIONS)
☐ Confidence Weight Optimization - Fine-tune all confidence weights based on comprehensive source authentication
☐ Geographic Coverage Assessment - Document final administrative level coverage achieved across all agents
☐ Temporal Coverage Assessment - Document final year-by-year coverage with absence validation
☐ Cross-Reference Matrix Completion - Final cross-validation against neighboring countries and regional patterns
☐ Duplicate Detection Final Pass - Systematic check for any remaining duplications across all agent results
☐ Source Chain Completion - Final attempt to resolve any broken links or incomplete references

**FINAL DATA COMPLETENESS VERIFICATION:**

☐ Gap Analysis Completion - Systematic review of any remaining temporal, geographic, or source gaps
☐ Zero-Transmission Period Validation - Final confirmation of epidemiologically relevant absence periods
☐ Data Point Verification - Spot-check validation of data points across all reliability levels
☐ Quality Score Consistency - Ensure consistent confidence weighting across all agents and source types
☐ Documentation Completeness - Verify ALL sources have complete metadata and dual-reference indexing
☐ Format Standardization - Final verification of JHU database format compliance
☐ Column Validation - Verify ALL required columns present with correct data types and formats
☐ Data Format Compliance - Ensure date formats (YYYY-MM-DD), location codes (AFR::{ISO}::), and numeric fields comply with standards
☐ Dual-Reference System Verification - Confirm source_index and source columns match exactly between metadata and data files
☐ Missing Data Documentation - Explicit documentation of any data that could not be recovered or validated

**DATASET FINALIZATION PROTOCOL:**

☐ Consolidated Dataset Assembly - Merge all agent results into final comprehensive dataset
☐ Final Metadata Integration - Consolidate metadata from all agents with enhanced dual-reference system
☐ Column Header Verification - Ensure all CSV files have correct column headers in proper order
☐ Data Type Validation - Verify numeric columns contain valid numbers, dates are properly formatted
☐ Mandatory Field Completion - Confirm all required fields are populated (Location, TL, TR, source_index, source)
☐ Index Number Continuity - Verify metadata Index numbers are sequential (1, 2, 3...) with no gaps
☐ Cross-File Consistency - Ensure source references match exactly between metadata.csv and cholera_data.csv
☐ Quality Assurance Summary - Generate comprehensive quality assessment across entire dataset
☐ Performance Metrics Compilation - Document agent-by-agent performance and cumulative effectiveness
☐ Methodology Documentation - Complete documentation of 6-agent workflow execution
☐ Uncertainty Quantification - Final assignment of confidence weights and uncertainty measures
☐ MOSAIC Integration Preparation - Format dataset for epidemiological modeling integration

**FINAL VALIDATION SWEEP:**

☐ Source Authentication Verification - Final check of source credibility and accessibility
☐ Data Logic Consistency - Mathematical and temporal consistency verification
☐ Regional Pattern Validation - Cross-validation with neighboring countries and known epidemic patterns
☐ Historical Context Verification - Validation against known historical cholera patterns for the region
☐ Quality Flag Assignment - Final assignment of quality flags for modeling sensitivity analysis

**COMPLETION CRITERIA**:
- All quality audit tasks completed comprehensively
- Complete dataset finalization achieved
- All documentation and validation completed
- Ready for MOSAIC epidemiological modeling integration

**FINAL DELIVERABLES:**
- Consolidated dataset with comprehensive quality audit complete
- Complete search methodology documentation across all 6 agents
- Comprehensive quality assessment and confidence analysis
- Final performance metrics summary with agent-by-agent breakdown
- **Complete end-to-end workflow execution time report**
- Quality assurance certificate for MOSAIC modeling integration
- Dataset preparation for epidemiological modeling with full uncertainty quantification

## MANDATORY FINAL STEP: UPDATE COUNTRY CHECKLIST

**Upon Agent 6 completion**: Update `./country_checklist.txt` with comprehensive 6-agent workflow performance:
```
☑ Angola (AGO) - Completed: YYYY-MM-DD HH:MM:SS UTC [6-AGENT WORKFLOW]
  Location: ./data/AGO/
  Files: search_report.txt, metadata.csv, cholera_data.csv, search_log.txt
  Data Points: [X] total entries (Complete 6-agent discovery achieved)
  Agents: 1[✓] 2[✓] 3[✓] 4[✓] 5[✓] 6[✓] (All agents completed)
  Duration: [X]h [X]m (Complete 6-agent workflow execution time)
  Quality: Level 1-2: [X]%, Level 3: [X]%, Level 4: [X]% (Quality distribution)
  Final Status: Ready for MOSAIC epidemiological modeling integration
```

**DO NOT ASK PERMISSION** to update this file - it's mandatory for completion tracking after Agent 6 finalization.

**FINAL CHECKPOINT REQUIREMENTS:**
*Final report: Total X sources found, Y observations added, Z% total improvement across 6-agent workflow*
*Quality metrics: A% Level 1-2 sources, B% Level 3 sources, C% Level 4 sources, complete quality distribution*
*Saturation confirmation: Discovery saturation definitively achieved across all 6 agents*
*Dataset quality: Final validation summary, comprehensive confidence assessment*
*Execution time: Total workflow runtime from start to finish*
*MOSAIC integration readiness: Dataset prepared for epidemiological modeling with full uncertainty quantification*
